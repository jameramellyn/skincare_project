{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jameramellyn/skincare_project/blob/main/K_cross_SkinTypeDetector.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4iuty9OKamwA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04fda3bd-8626-4317-8182-367ece70b832"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (11.1.0)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "!pip install Pillow\n",
        "#train test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from numpy import asarray\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Input, Conv2D, MaxPooling2D, Flatten\n",
        "from sklearn.metrics import confusion_matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OxuhqXVQarqY",
        "outputId": "0df44e3a-a0ec-4598-9ef4-0162fd5101d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WugmDZJ3Edc",
        "outputId": "2e20eb38-47c9-4d6d-e654-503e13a68557"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "!pwd\n",
        "images = '/content/drive/MyDrive/SkincareProject/Oily-Dry-Skin-Types'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "aQ9Yc-OXjrJd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "outputId": "cb79c191-a163-44f8-f8c5-bf395f61280b"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/SkincareProject/Oily-Dry-Skin-Types/train'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-93f552c50170>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mtrain_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/SkincareProject/Oily-Dry-Skin-Types/train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mval_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/SkincareProject/Oily-Dry-Skin-Types/valid\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mtest_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/SkincareProject/Oily-Dry-Skin-Types/test\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-93f552c50170>\u001b[0m in \u001b[0;36mcreate_df\u001b[0;34m(base)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mdd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"images\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"labels\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/SkincareProject/Oily-Dry-Skin-Types/train'"
          ]
        }
      ],
      "source": [
        "#the dataset only comes with images that have been sorted into folders, but not formally labelled\n",
        "#this function will help to label each of the images as the dataframe is being created\n",
        "label_index = {\"dry\": 0, \"normal\": 1, \"oily\": 2}\n",
        "index_label = {0: \"dry\", 1: \"normal\", 2: \"oily\"}\n",
        "\n",
        "def create_df(base):\n",
        "    dd = {\"images\": [], \"labels\": []}\n",
        "    for i in os.listdir(base):\n",
        "        label = os.path.join(base, i)\n",
        "        for j in os.listdir(label):\n",
        "            img = os.path.join(label, j)\n",
        "            dd[\"images\"] += [img]\n",
        "            dd[\"labels\"] += [label_index[i]]\n",
        "    return pd.DataFrame(dd)\n",
        "\n",
        "\n",
        "train_df = create_df(\"/content/drive/MyDrive/SkincareProject/Oily-Dry-Skin-Types/train\")\n",
        "val_df = create_df(\"/content/drive/MyDrive/SkincareProject/Oily-Dry-Skin-Types/valid\")\n",
        "test_df = create_df(\"/content/drive/MyDrive/SkincareProject/Oily-Dry-Skin-Types/test\")\n",
        "\n",
        "df = pd.concat([train_df, val_df, test_df], axis=0)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "innVNAaGTpQL"
      },
      "outputs": [],
      "source": [
        "def load_image(file_path):\n",
        "    with Image.open(file_path) as img:\n",
        "        img = img.convert('RGB')  # Ensure image is in RGB mode\n",
        "        return np.array(img)\n",
        "\n",
        "def extract_image_data(file_path):\n",
        "    img_array = load_image(file_path)\n",
        "    height, width, channels = img_array.shape\n",
        "    return pd.Series({\n",
        "        'height': height,\n",
        "        'width': width,\n",
        "        'channels': channels,\n",
        "        'image_array': img_array\n",
        "    })\n",
        "\n",
        "# Apply the function to each file path in the dataframe\n",
        "df_data = train_df.iloc[:, 0].apply(extract_image_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_data.head()"
      ],
      "metadata": {
        "id": "xlQUJkCdrba-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.concat([df_data, train_df.iloc[:, 1]], axis=1)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "y6QDxjglq5dL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Input\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "metadata": {
        "id": "35PeYwvxW_Ba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plotLoss(history, fold_number):\n",
        "    TRAINING_LOSS = history.history['loss']\n",
        "    VALIDATION_LOSS = history.history.get('val_loss')  # Validation loss if available\n",
        "    EPOCHS = range(1, len(TRAINING_LOSS) + 1)\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "\n",
        "    # Plot training loss\n",
        "    plt.plot(EPOCHS, TRAINING_LOSS, 'b', label='Training Loss')\n",
        "\n",
        "    # Plot validation loss (if available)\n",
        "    if VALIDATION_LOSS:\n",
        "        plt.plot(EPOCHS, VALIDATION_LOSS, 'r', label='Validation Loss')\n",
        "\n",
        "    # Set y-axis to range from 0 to 5\n",
        "    plt.ylim(0, 5)\n",
        "\n",
        "    plt.title(f'Training and Validation Loss (Fold {fold_number})')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "WywLfHD9HBPF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plotAccuracy(history, fold_number):\n",
        "    TRAINING_ACCURACY = history.history['accuracy']\n",
        "    VALIDATION_ACCURACY = history.history.get('val_accuracy')  # Validation accuracy if available\n",
        "    EPOCHS = range(1, len(TRAINING_ACCURACY) + 1)\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "\n",
        "    # Plot training accuracy\n",
        "    plt.plot(EPOCHS, TRAINING_ACCURACY, 'b', label='Training Accuracy')\n",
        "\n",
        "    # Plot validation accuracy (if available)\n",
        "    if VALIDATION_ACCURACY:\n",
        "        plt.plot(EPOCHS, VALIDATION_ACCURACY, 'r', label='Validation Accuracy')\n",
        "\n",
        "    # Set y-axis to range from 0 to 1 (as accuracy is typically between 0 and 1)\n",
        "    plt.ylim(0, 1)\n",
        "\n",
        "    plt.title(f'Training and Validation Accuracy (Fold {fold_number})')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "wTJZWEqEPv0a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7wtmZdRgs1-W"
      },
      "outputs": [],
      "source": [
        "#defining the variables\n",
        "height = 640\n",
        "width = 640\n",
        "num_classes = 3\n",
        "channels = 3\n",
        "\n",
        "# normalize\n",
        "def normalize(df):\n",
        "    normalized_images = []\n",
        "    for index, row in df.iterrows():\n",
        "      # Extract the image array from the first column\n",
        "      image_array = row[3]\n",
        "      # Ensure the array is in float32 format\n",
        "      image_array = image_array.astype('float32')\n",
        "      # Normalize the pixel values to the range [0, 1]\n",
        "      image_array /= 255.0\n",
        "      # Append the normalized image to a new list\n",
        "      normalized_images.append(image_array)\n",
        "    # Create a new DataFrame with the normalized images\n",
        "    df[0] = normalized_images\n",
        "    return df\n",
        "\n",
        "def kCross(df,i):\n",
        "    # Split the data into training and testing sets\n",
        "    train_df, test_df = train_test_split(df, test_size=0.2, random_state=i)\n",
        "    x_train, y_train = train_df.drop('labels', axis=1), train_df['labels']\n",
        "    x_test, y_test = test_df.drop('labels', axis=1), test_df['labels']\n",
        "\n",
        "    #Normalize training and testing data\n",
        "    x_train_norm = normalize(x_train)\n",
        "    x_test_norm = normalize(x_test)\n",
        "\n",
        "    # Extract the normalized image arrays and convert them to a NumPy array\n",
        "    x_train = np.stack(x_train_norm['image_array'].values)\n",
        "    x_test = np.stack(x_test_norm['image_array'].values)\n",
        "\n",
        "    #validation\n",
        "    x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=i)\n",
        "\n",
        "    #transferring to one-hot\n",
        "    y_train_oh = tf.keras.utils.to_categorical(y_train, 3)\n",
        "    y_test_oh = tf.keras.utils.to_categorical(y_test, 3)\n",
        "    y_val_oh = tf.keras.utils.to_categorical(y_val, 3)\n",
        "\n",
        "    # create CNN structure\n",
        "    model = Sequential()\n",
        "    model.add(Input(shape=(height, width, 3)))\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu')) # notice no MaxPool after this one\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dense(3, activation='softmax'))\n",
        "    model.summary()\n",
        "\n",
        "    # compile and train model\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Train the model with validation data and capture the history\n",
        "    history = model.fit(x_train, y_train_oh, epochs=10, batch_size=32, validation_data=(x_val, y_val_oh))\n",
        "\n",
        "    # Plot the training/validation loss for this fold\n",
        "    plotLoss(history, fold_number=i+1)\n",
        "    plotAccuracy(history, fold_number=i+1)\n",
        "\n",
        "    # evaluate accuracy\n",
        "    y_pred = model.predict(x_test)\n",
        "    y_pred = tf.argmax(y_pred, axis=1)\n",
        "    loss, acc = model.evaluate(x_test, y_test_oh)\n",
        "\n",
        "    print(f\"Fold {i+1} - Test accuracy:\", acc)\n",
        "    print(f\"Confusion matrix for fold {i+1}:\\n\", confusion_matrix(y_test, y_pred))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E4D3qaRJ5vfz"
      },
      "outputs": [],
      "source": [
        "for i in range(5):\n",
        "  kCross(df,i)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}